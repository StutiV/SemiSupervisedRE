{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rel_ext_task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJL0fpiZAt8A"
      },
      "source": [
        "import random\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "import rel_ext\n",
        "import utils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8kgb9n5CJHh"
      },
      "source": [
        "#set all the random seeds for reproducibility\n",
        "#only system seed relevant here\n",
        "utils.fix_random_seeds()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPO3KjVUCX4X"
      },
      "source": [
        "rel_ext_data_home = os.path.join('data', 'rel_ext_data')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvF2r_XkCe93"
      },
      "source": [
        "# ***The Corpus***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcLy9ey6CcGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6658c79-8c08-446b-ff94-013ec4681f4a"
      },
      "source": [
        "corpus = rel_ext.Corpus(os.path.join(rel_ext_data_home, 'corpus.tsv.gz'))\n",
        "\n",
        "print('Read {0:,} examples'.format(len(corpus)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 331,696 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP2SinfKCt_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1bfd4b-e009-4258-855c-d4bdbee20a66"
      },
      "source": [
        "print(corpus.examples[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example(entity_1='New_Mexico', entity_2='Arizona', left='to all Spanish-occupied lands . The horno has a beehive shape and uses wood as the only heat source . The procedure still used in parts of', mention_1='New Mexico', middle='and', mention_2='Arizona', right='is to build a fire inside the Horno and , when the proper amount of time has passed , remove the embers and ashes and insert the', left_POS='to/TO all/DT Spanish-occupied/JJ lands/NNS ./. The/DT horno/NN has/VBZ a/DT beehive/NN shape/NN and/CC uses/VBZ wood/NN as/IN the/DT only/JJ heat/NN source/NN ./. The/DT procedure/NN still/RB used/VBN in/IN parts/NNS of/IN', mention_1_POS='New/NNP Mexico/NNP', middle_POS='and/CC', mention_2_POS='Arizona/NNP', right_POS='is/VBZ to/TO build/VB a/DT fire/NN inside/IN the/DT Horno/NNP and/CC ,/, when/WRB the/DT proper/JJ amount/NN of/IN time/NN has/VBZ passed/VBN ,/, remove/VB the/DT embers/NNS and/CC ashes/NNS and/CC insert/VB the/DT')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNzkPy0fDLC3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4078e6b1-e94d-4f08-b98d-12a1cabdb16a"
      },
      "source": [
        "#taking a closer look at one of the examples\n",
        "ex = corpus.examples[1]\n",
        "\n",
        "' '.join((ex.left, ex.mention_1, ex.middle, ex.mention_2, ex.right))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'to all Spanish-occupied lands . The horno has a beehive shape and uses wood as the only heat source . The procedure still used in parts of New Mexico and Arizona is to build a fire inside the Horno and , when the proper amount of time has passed , remove the embers and ashes and insert the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RgXjxv0DMlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "581f4ecb-32c5-4bfb-b7fa-f68239ab7b08"
      },
      "source": [
        "#looking at entities over the corpus and seeing the most common ones\n",
        "counter = Counter()\n",
        "for example in corpus.examples:\n",
        "    counter[example.entity_1] += 1\n",
        "    counter[example.entity_2] += 1\n",
        "print('The corpus contains {} entities'.format(len(counter)))\n",
        "counts = sorted([(count, key) for key, count in counter.items()], reverse=True)\n",
        "print('The most common entities are:')\n",
        "for count, key in counts[:20]:\n",
        "    print('{:10d} {}'.format(count, key))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The corpus contains 95909 entities\n",
            "The most common entities are:\n",
            "      8137 India\n",
            "      5240 England\n",
            "      4121 France\n",
            "      4040 Germany\n",
            "      3937 Australia\n",
            "      3779 Canada\n",
            "      3633 Italy\n",
            "      3138 California\n",
            "      2894 New_York_City\n",
            "      2745 Pakistan\n",
            "      2213 New_Zealand\n",
            "      2183 New_York\n",
            "      2148 United_Kingdom\n",
            "      2030 Spain\n",
            "      2005 Japan\n",
            "      1891 Russia\n",
            "      1806 Philippines\n",
            "      1748 Malaysia\n",
            "      1721 Indonesia\n",
            "      1670 China\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XA2e3wjDcTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8003cc07-ff01-481c-d456-9296a8db1e5a"
      },
      "source": [
        "#finding examples containing 'Elon Musk' and 'Tesla Motors'\n",
        "#only mentions examples where 'Elon Musk' was mentioned first and 'Tesla Motors' was mentioned second\n",
        "corpus.show_examples_for_pair('Elon_Musk', 'Tesla_Motors')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The first of 5 examples for Elon_Musk and Tesla_Motors is:\n",
            "Example(entity_1='Elon_Musk', entity_2='Tesla_Motors', left='space for a while , here ’ s what might be launching Americans into space in the next decade . Falcon 9 From sometimes Canadian , South African & American', mention_1='Elon Musk', middle='‘ s company Space X . Musk is a PayPal alumni and', mention_2='Tesla Motors', right='co-founder - remember that latter company name for future trivia questions and/or a remake of Back to the Future . After several successful launches on their Falcon', left_POS=\"space/NN for/IN a/DT while/NN ,/, here/RB '/'' s/VBZ what/WP might/MD be/VB launching/VBG Americans/NNPS into/IN space/NN in/IN the/DT next/JJ decade/NN ./. Falcon/NNP 9/CD From/IN sometimes/RB Canadian/JJ ,/, South/JJ African/NNP &/CC American/NNP\", mention_1_POS='Elon/NNP Musk/NNP', middle_POS='`/`` s/NNS company/NN Space/NN X/NN ./. Musk/NNP is/VBZ a/DT PayPal/NNP alumni/NNS and/CC', mention_2_POS='Tesla/NNP Motors/NNPS', right_POS='co-founder/NN -/: remember/VB that/DT latter/JJ company/NN name/NN for/IN future/JJ trivia/NNS questions/NNS and/or/CC a/DT remake/NN of/IN Back/RB to/TO the/DT Future/NNP ./. After/IN several/JJ successful/JJ launches/NNS on/IN their/PRP$ Falcon/NN')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCrEBzGcEFIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0fd8b1-2e30-476f-ff7a-acc2bc782d3e"
      },
      "source": [
        "#examples that have the above entities in reverse order\n",
        "corpus.show_examples_for_pair('Tesla_Motors', 'Elon_Musk')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The first of 2 examples for Tesla_Motors and Elon_Musk is:\n",
            "Example(entity_1='Tesla_Motors', entity_2='Elon_Musk', left='their factory in Hethel . If you want to see one in action , Robert Scoble got a ride in the first production model , driven by', mention_1='Tesla Motors', middle='chairman', mention_2='Elon Musk', right='. Needless to say he got the whole thing on video , and covers a lot of technical details about the car – this is the', left_POS='their/PRP$ factory/NN in/IN Hethel/NNP ./. If/IN you/PRP want/VBP to/TO see/VB one/CD in/IN action/NN ,/, Robert/NNP Scoble/NNP got/VBD a/DT ride/NN in/IN the/DT first/JJ production/NN model/NN ,/, driven/VBN by/IN', mention_1_POS='Tesla/NNP Motors/NNPS', middle_POS='chairman/NN', mention_2_POS='Elon/NNP Musk/NNP', right_POS='./. Needless/JJ to/TO say/VB he/PRP got/VBD the/DT whole/JJ thing/NN on/IN video/NN ,/, and/CC covers/VBZ a/DT lot/NN of/IN technical/JJ details/NNS about/IN the/DT car/NN --/: this/DT is/VBZ the/DT')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxeKDrGoEfbZ"
      },
      "source": [
        "# ***The Knowledge Base***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKppxxzjE5Xg"
      },
      "source": [
        "*The data distribution was ultimately derived from https://freebase-easy.cs.uni-freiburg.de/dump/ . The KB is a collection of relation triples of the form (relation, subject, object), such as:*\n",
        "\n",
        "\n",
        "*   (place_of_birth, Barack_Obama, Honolulu)\n",
        "*   (has_spouse, Barack_Obama, Michelle_Obama)\n",
        "*   (author, The_Audacity_of_Hope, Barack_Obama) \n",
        "\n",
        "*The class makes it easy and efficient to look up triples in the KB using both relations and entities.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOy4EiJYFD0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8436734-08a9-411e-ceff-f357c087e446"
      },
      "source": [
        "kb = rel_ext.KB(os.path.join(rel_ext_data_home, 'kb.tsv.gz'))\n",
        "\n",
        "print('Read {0:,} KB triples'.format(len(kb)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 45,884 KB triples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7J17-fNGXVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd961a97-054a-477c-cb42-43a5ddeeb323"
      },
      "source": [
        "#how many relations?\n",
        "len(kb.all_relations)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg5x6ZAUGjaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e91087-d1e0-4b94-b438-ffd3d2f2c625"
      },
      "source": [
        "#how many triples does each relation contain?\n",
        "for rel in kb.all_relations:\n",
        "    print('{:12d} {}'.format(len(kb.get_triples_for_relation(rel)), rel))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        1702 adjoins\n",
            "        2671 author\n",
            "         522 capital\n",
            "       18681 contains\n",
            "        3947 film_performance\n",
            "        1960 founders\n",
            "         824 genre\n",
            "        2563 has_sibling\n",
            "        2994 has_spouse\n",
            "        2542 is_a\n",
            "        1598 nationality\n",
            "        1586 parents\n",
            "        1097 place_of_birth\n",
            "         831 place_of_death\n",
            "        1216 profession\n",
            "        1150 worked_at\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJeT-NsdGqOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc80020-56c8-49fd-fb7b-97711fb914a6"
      },
      "source": [
        "#lookin at one example from each relation to see what they mean\n",
        "for rel in kb.all_relations:\n",
        "    print(tuple(kb.get_triples_for_relation(rel)[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('adjoins', 'France', 'Spain')\n",
            "('author', 'Uncle_Silas', 'Sheridan_Le_Fanu')\n",
            "('capital', 'Panama', 'Panama_City')\n",
            "('contains', 'Brickfields', 'Kuala_Lumpur_Sentral_railway_station')\n",
            "('film_performance', 'Colin_Hanks', 'The_Great_Buck_Howard')\n",
            "('founders', 'Lashkar-e-Taiba', 'Hafiz_Muhammad_Saeed')\n",
            "('genre', '8_Simple_Rules', 'Sitcom')\n",
            "('has_sibling', 'Ari_Emanuel', 'Rahm_Emanuel')\n",
            "('has_spouse', 'Percy_Bysshe_Shelley', 'Mary_Shelley')\n",
            "('is_a', 'Bhanu_Athaiya', 'Costume_designer')\n",
            "('nationality', 'Ruben_Rausing', 'Sweden')\n",
            "('parents', 'Rosanna_Davison', 'Chris_de_Burgh')\n",
            "('place_of_birth', 'William_Penny_Brookes', 'Much_Wenlock')\n",
            "('place_of_death', 'Jean_Drapeau', 'Montreal')\n",
            "('profession', 'Rufus_Wainwright', 'Actor')\n",
            "('worked_at', 'Brian_Greene', 'Columbia_University')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq764m1SGzp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055e13c5-9fd3-4e1a-c392-c51f85b1bdfd"
      },
      "source": [
        "#kb.get_triples_for_entities() method allows us to look up triples by the entities they contain. \n",
        "#using it to see what relation(s) hold between France and Germany\n",
        "kb.get_triples_for_entities('France', 'Germany')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[KBTriple(rel='adjoins', sbj='France', obj='Germany')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXTW7jOYHPqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a734edd-8adb-4873-fbf7-e9700cd8cc3d"
      },
      "source": [
        "#most relations in the KB are asymmetric\n",
        "#but some relations like 'adjoins' and 'has sibling' are symmetric,so the vice versa would also be true\n",
        "kb.get_triples_for_entities('Germany', 'France')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[KBTriple(rel='adjoins', sbj='Germany', obj='France')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pthQCISeIQ8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eaac6d0-a24b-48ec-8b12-32ddce28803e"
      },
      "source": [
        "#there might be cases where there are more than one relation, even in one direction\n",
        "#for instance, Ptolemly XIII was the brother and husband of Cleopatra\n",
        "kb.get_triples_for_entities('Cleopatra', 'Ptolemy_XIII_Theos_Philopator')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[KBTriple(rel='has_sibling', sbj='Cleopatra', obj='Ptolemy_XIII_Theos_Philopator'),\n",
              " KBTriple(rel='has_spouse', sbj='Cleopatra', obj='Ptolemy_XIII_Theos_Philopator')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD_X3OlQIugt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194df2f5-266a-4437-bf8f-078672b9fc81"
      },
      "source": [
        "#the distribution of entities in the KB\n",
        "counter = Counter()\n",
        "for kbt in kb.kb_triples:\n",
        "    counter[kbt.sbj] += 1\n",
        "    counter[kbt.obj] += 1\n",
        "print('The KB contains {:,} entities'.format(len(counter)))\n",
        "counts = sorted([(count, key) for key, count in counter.items()], reverse=True)\n",
        "print('The most common entities are:')\n",
        "for count, key in counts[:20]:\n",
        "    print('{:10d} {}'.format(count, key))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The KB contains 40,141 entities\n",
            "The most common entities are:\n",
            "       945 England\n",
            "       786 India\n",
            "       438 Italy\n",
            "       414 France\n",
            "       412 California\n",
            "       400 Germany\n",
            "       372 United_Kingdom\n",
            "       366 Canada\n",
            "       302 New_York_City\n",
            "       247 New_York\n",
            "       236 Australia\n",
            "       219 Philippines\n",
            "       215 Japan\n",
            "       212 Scotland\n",
            "       208 Russia\n",
            "       198 Actor\n",
            "       172 Pakistan\n",
            "       170 Ontario\n",
            "       169 Ireland\n",
            "       168 New_Zealand\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdQMh5eqJJLX"
      },
      "source": [
        "## ***Joining the corpus and the KB***\n",
        "In order to leverage the distant supervision paradigm, we'll need to connect information in the corpus with information in the KB. There are two possibilities, depending on how we formulate our prediction problem:\n",
        "\n",
        "Use the KB to generate labels for the corpus. If our problem is to classify a pair of entity mentions in a specific example in the corpus, then we can use the KB to provide labels for training examples. \n",
        "\n",
        "We'll formulate our prediction problem such that the input is a pair of entities, and the goal is to predict what relation(s) the pair belongs to. The KB will provide the labels, and the corpus will provide the features.\n",
        "\n",
        "We've created a Dataset class which combines a corpus and a KB, and provides a variety of convenience methods for the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSD2bV10I5K-"
      },
      "source": [
        "dataset = rel_ext.Dataset(corpus, kb)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IERX1O3tLrey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e8935a-240d-4e95-df79-f20714112485"
      },
      "source": [
        "#determining how many relations we have for each triple in the KB\n",
        "#computing averages per relation\n",
        "dataset.count_examples()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             examples\n",
            "relation               examples    triples    /triple\n",
            "--------               --------    -------    -------\n",
            "adjoins                   58854       1702      34.58\n",
            "author                    11768       2671       4.41\n",
            "capital                    7443        522      14.26\n",
            "contains                  75952      18681       4.07\n",
            "film_performance           8994       3947       2.28\n",
            "founders                   5846       1960       2.98\n",
            "genre                      1576        824       1.91\n",
            "has_sibling                8525       2563       3.33\n",
            "has_spouse                12013       2994       4.01\n",
            "is_a                       5112       2542       2.01\n",
            "nationality                3403       1598       2.13\n",
            "parents                    3802       1586       2.40\n",
            "place_of_birth             1657       1097       1.51\n",
            "place_of_death             1523        831       1.83\n",
            "profession                 1851       1216       1.52\n",
            "worked_at                  3226       1150       2.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brp8T0C6MCRc"
      },
      "source": [
        "***Negative Instances :***\n",
        "In order to apply distant supervision paradigm, we also need some negative instances (entity pairs which do not belong to any known relation).\n",
        "We assign these entities the special relation called `No_Relation`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTiMNUcaL3lw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70cb4d5c-f50a-4f82-abeb-c30d2e894301"
      },
      "source": [
        "unrelated_pairs = dataset.find_unrelated_pairs()\n",
        "print('Found {0:,} unrelated pairs, including:'.format(len(unrelated_pairs)))\n",
        "for pair in list(unrelated_pairs)[:10]:\n",
        "    print('   ', pair)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 247,405 unrelated pairs, including:\n",
            "    ('Aratus', 'Seneca_the_Younger')\n",
            "    ('Rocky_Mountains', 'Czech_Republic')\n",
            "    ('Estate_agent', 'Canada')\n",
            "    ('Jungfrau', 'Zermatt')\n",
            "    ('Charles_Eames', 'Gregory_Ain')\n",
            "    ('Guwahati', 'Ahmedabad')\n",
            "    ('Sarah', 'Book_of_Genesis')\n",
            "    ('BRCA1', 'BRCA2')\n",
            "    ('Cuddalore', 'Chittoor')\n",
            "    ('Heinz_von_Foerster', 'Hans_Moravec')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de4FSaFUOyVD"
      },
      "source": [
        "Our prediction problem is a multi-label classification. \n",
        "\n",
        "There are a number of ways to approach multi-label classification, but the most obvious is the binary relevance method ( factors multi-label classification over n labels into n independent binary classification problems, one for each label). \n",
        "\n",
        "*Disadvantage:* by treating the binary classification problems as independent, it fails to exploit correlations between labels. \n",
        "\n",
        "\n",
        "So our problem will be to take as input an entity pair and a candidate relation (label), and to return a binary prediction as to whether the entity pair belongs to the relation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNb840YNmMti"
      },
      "source": [
        "# ***Building Datasets***\n",
        "\n",
        "We'll now have a function to build datasets that are suitable for training and evaluating the predictive models. Characteristics of the datasets:\n",
        "\n",
        "\n",
        "*   since our problem has been formulated as a multi label classification, we'll be training separate models for each relation and won't build a single dataset.\n",
        "We'll build a dataset for each relation.\n",
        "\n",
        "*  The dataset for each relation will consist of two parallel lists:\n",
        "        1.   A list of candidate `KBTriples` which combine the given relation with a pair of entities.\n",
        "        2.   A corresponding list of boolean labels indicating whether the given `KBTriple` belongs to the KB.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTn6aQT0M5G1"
      },
      "source": [
        "kbts_by_rel, labels_by_rel = dataset.build_dataset(\n",
        "    include_positive=True, sampling_rate=0.1, seed=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTtqrENApL9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1f0c0d-5db5-47b4-fef0-57384832b23f"
      },
      "source": [
        "print(kbts_by_rel['adjoins'][0], labels_by_rel['adjoins'][0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KBTriple(rel='adjoins', sbj='France', obj='Spain') True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OI7INJwpPkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0313a0-12b3-4bf5-ec9c-98a14883697a"
      },
      "source": [
        "print(kbts_by_rel['capital'][637], labels_by_rel['capital'][637])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KBTriple(rel='capital', sbj='Sigmund_Freud', obj='Magnus_Hirschfeld') False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5ULeGfJppl2"
      },
      "source": [
        "# ***Splitting the Data***\n",
        "tiny split = 1%\n",
        "\n",
        "train split= 74%\n",
        "\n",
        "dev split= 25%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHSUtynDp8pi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91be7f2f-3804-4c14-c5ff-0ecb2dc3e50d"
      },
      "source": [
        "splits = dataset.build_splits(\n",
        "    split_names=['tiny', 'train', 'dev'],\n",
        "    split_fracs=[0.01, 0.74, 0.25],\n",
        "    seed=1)\n",
        "\n",
        "splits"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'all': Corpus with 331,696 examples; KB with 45,884 triples,\n",
              " 'dev': Corpus with 79,219 examples; KB with 11,210 triples,\n",
              " 'tiny': Corpus with 3,474 examples; KB with 445 triples,\n",
              " 'train': Corpus with 249,003 examples; KB with 34,229 triples}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubBGzJPkqBZ8"
      },
      "source": [
        "# ***Evaluating***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgvz4qqAqqmU"
      },
      "source": [
        "def lift(f):\n",
        "    return lambda xs: [f(x) for x in xs]\n",
        "\n",
        "def make_random_classifier(p=0.50):\n",
        "    def random_classify(kb_triple):\n",
        "        return random.random() < p\n",
        "    return lift(random_classify)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfgNVw2Pqvit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb2da48-d510-45cc-8099-df46ff18b9a0"
      },
      "source": [
        "def find_common_middles(split, top_k=3, show_output=False):\n",
        "    corpus = split.corpus\n",
        "    kb = split.kb\n",
        "    mids_by_rel = {\n",
        "        'fwd': defaultdict(lambda: defaultdict(int)),\n",
        "        'rev': defaultdict(lambda: defaultdict(int))}\n",
        "    for rel in kb.all_relations:\n",
        "        for kbt in kb.get_triples_for_relation(rel):\n",
        "            for ex in corpus.get_examples_for_entities(kbt.sbj, kbt.obj):\n",
        "                mids_by_rel['fwd'][rel][ex.middle] += 1\n",
        "            for ex in corpus.get_examples_for_entities(kbt.obj, kbt.sbj):\n",
        "                mids_by_rel['rev'][rel][ex.middle] += 1\n",
        "    def most_frequent(mid_counter):\n",
        "        return sorted([(cnt, mid) for mid, cnt in mid_counter.items()], reverse=True)[:top_k]\n",
        "    for rel in kb.all_relations:\n",
        "        for dir in ['fwd', 'rev']:\n",
        "            top = most_frequent(mids_by_rel[dir][rel])\n",
        "            if show_output:\n",
        "                for cnt, mid in top:\n",
        "                    print('{:20s} {:5s} {:10d} {:s}'.format(rel, dir, cnt, mid))\n",
        "            mids_by_rel[dir][rel] = set([mid for cnt, mid in top])\n",
        "    return mids_by_rel\n",
        "\n",
        "_ = find_common_middles(splits['train'], show_output=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adjoins              fwd         7667 ,\n",
            "adjoins              fwd         5134 and\n",
            "adjoins              fwd          903 , and\n",
            "adjoins              rev         4582 ,\n",
            "adjoins              rev         3000 and\n",
            "adjoins              rev          507 , and\n",
            "author               fwd         1007 by\n",
            "author               fwd          124 ,\n",
            "author               fwd          105 , by\n",
            "author               rev          816 's\n",
            "author               rev          210 ‘ s\n",
            "author               rev          142 ’ s\n",
            "capital              fwd           33 ,\n",
            "capital              fwd           17 , after\n",
            "capital              fwd           14 in\n",
            "capital              rev         2506 ,\n",
            "capital              rev          121 in\n",
            "capital              rev           73 , the capital of\n",
            "contains             fwd          319 's\n",
            "contains             fwd          296 ,\n",
            "contains             fwd          211 (\n",
            "contains             rev        18511 ,\n",
            "contains             rev         4160 in\n",
            "contains             rev          603 in the\n",
            "film_performance     fwd          283 in\n",
            "film_performance     fwd          151 's\n",
            "film_performance     fwd           96 film\n",
            "film_performance     rev          183 with\n",
            "film_performance     rev          128 , starring\n",
            "film_performance     rev           97 opposite\n",
            "founders             fwd           78 founder\n",
            "founders             fwd           56 co-founder\n",
            "founders             fwd           44 ,\n",
            "founders             rev          140 's\n",
            "founders             rev           66 ‘ s\n",
            "founders             rev           62 of the\n",
            "genre                fwd           20 , a\n",
            "genre                fwd           13 in 1994 , he became a central figure in the\n",
            "genre                fwd           11 is a\n",
            "genre                rev           98 ,\n",
            "genre                rev           60 series\n",
            "genre                rev           17 show\n",
            "has_sibling          fwd         1115 and\n",
            "has_sibling          fwd          545 ,\n",
            "has_sibling          fwd          125 , and\n",
            "has_sibling          rev          676 and\n",
            "has_sibling          rev          371 ,\n",
            "has_sibling          rev           68 , and\n",
            "has_spouse           fwd         1825 and\n",
            "has_spouse           fwd          379 ,\n",
            "has_spouse           fwd           97 and his wife\n",
            "has_spouse           rev         1183 and\n",
            "has_spouse           rev          225 ,\n",
            "has_spouse           rev           74 and his wife\n",
            "is_a                 fwd          100 ,\n",
            "is_a                 fwd           44 family ,\n",
            "is_a                 fwd           34 , a\n",
            "is_a                 rev          175 ,\n",
            "is_a                 rev           73 \n",
            "is_a                 rev           47 of\n",
            "nationality          fwd          264 of\n",
            "nationality          fwd           70 in\n",
            "nationality          fwd           27 from\n",
            "nationality          rev           51 ,\n",
            "nationality          rev           24 by\n",
            "nationality          rev           18 under\n",
            "parents              fwd           64 , son of\n",
            "parents              fwd           45 and\n",
            "parents              fwd           42 ,\n",
            "parents              rev          187 and\n",
            "parents              rev          151 ,\n",
            "parents              rev           42 and his son\n",
            "place_of_birth       fwd           85 of\n",
            "place_of_birth       fwd           50 was born in\n",
            "place_of_birth       fwd           35 in\n",
            "place_of_birth       rev           15 by\n",
            "place_of_birth       rev           15 ,\n",
            "place_of_birth       rev            9 -born Franciscan scholar\n",
            "place_of_death       fwd           65 in\n",
            "place_of_death       fwd           48 of\n",
            "place_of_death       fwd            9 at\n",
            "place_of_death       rev            9 ,\n",
            "place_of_death       rev            8 mayor\n",
            "place_of_death       rev            7 by\n",
            "profession           fwd           85 ,\n",
            "profession           fwd           27 , a\n",
            "profession           fwd           26 and\n",
            "profession           rev          101 ,\n",
            "profession           rev           67 \n",
            "profession           rev           24 and\n",
            "worked_at            fwd           94 of\n",
            "worked_at            fwd           57 at\n",
            "worked_at            fwd           57 's\n",
            "worked_at            rev           34 ,\n",
            "worked_at            rev           19 with\n",
            "worked_at            rev           18 co-founder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBHHPTpJqyt4"
      },
      "source": [
        "def train_top_k_middles_classifier(top_k=3):\n",
        "    split = splits['train']\n",
        "    corpus = split.corpus\n",
        "    top_k_mids_by_rel = find_common_middles(split=split, top_k=top_k)\n",
        "    def classify(kb_triple):\n",
        "        fwd_mids = top_k_mids_by_rel['fwd'][kb_triple.rel]\n",
        "        rev_mids = top_k_mids_by_rel['rev'][kb_triple.rel]\n",
        "        for ex in corpus.get_examples_for_entities(kb_triple.sbj, kb_triple.obj):\n",
        "            if ex.middle in fwd_mids:\n",
        "                return True\n",
        "        for ex in corpus.get_examples_for_entities(kb_triple.obj, kb_triple.sbj):\n",
        "            if ex.middle in rev_mids:\n",
        "                return True\n",
        "        return False\n",
        "    return lift(classify)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i43ohBiIq1lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1393f3d-0384-4d95-8e1d-96dc0ec8686d"
      },
      "source": [
        "rel_ext.evaluate(splits, train_top_k_middles_classifier())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "relation              precision     recall    f-score    support       size\n",
            "------------------    ---------  ---------  ---------  ---------  ---------\n",
            "adjoins                   0.272      0.285      0.274        407       7057\n",
            "author                    0.325      0.078      0.198        657       7307\n",
            "capital                   0.093      0.159      0.101        126       6776\n",
            "contains                  0.593      0.064      0.223       4487      11137\n",
            "film_performance          0.625      0.005      0.025        984       7634\n",
            "founders                  0.148      0.038      0.094        469       7119\n",
            "genre                     0.000      0.000      0.000        205       6855\n",
            "has_sibling               0.261      0.176      0.238        625       7275\n",
            "has_spouse                0.348      0.211      0.308        754       7404\n",
            "is_a                      0.071      0.024      0.051        618       7268\n",
            "nationality               0.120      0.036      0.082        386       7036\n",
            "parents                   0.080      0.067      0.077        390       7040\n",
            "place_of_birth            0.019      0.007      0.014        282       6932\n",
            "place_of_death            0.028      0.014      0.023        209       6859\n",
            "profession                0.039      0.039      0.039        308       6958\n",
            "worked_at                 0.054      0.020      0.040        303       6953\n",
            "------------------    ---------  ---------  ---------  ---------  ---------\n",
            "macro-average             0.192      0.076      0.112      11210     117610\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11179102963297724"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aihQx64ew5V-"
      },
      "source": [
        "# ***Building a Classifier***\n",
        "\n",
        "**Featurizers**\n",
        "\n",
        "Finds all the corpus examples containing the two entities in the `KBTriple`, breaks the phrase appearing between the two entity mentions into words, and counts the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5Sj1ubCwb2P"
      },
      "source": [
        "#a simple bag of words featurizer\n",
        "# no distinction between 'forward' and 'reverse' examples\n",
        "\n",
        "def simple_bag_of_words_featurizer(kbt, corpus, feature_counter):\n",
        "    for ex in corpus.get_examples_for_entities(kbt.sbj, kbt.obj):\n",
        "        for word in ex.middle.split(' '):\n",
        "            feature_counter[word] += 1\n",
        "    for ex in corpus.get_examples_for_entities(kbt.obj, kbt.sbj):\n",
        "        for word in ex.middle.split(' '):\n",
        "            feature_counter[word] += 1\n",
        "    return feature_counter"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sZUnM0DxrYg"
      },
      "source": [
        "How the featurizer works on a single example :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYvwXdKTxiEQ",
        "outputId": "8a671e4e-b75e-46a5-804c-619a94f5c365"
      },
      "source": [
        "kbt = kb.kb_triples[0]\n",
        "\n",
        "kbt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KBTriple(rel='contains', sbj='Brickfields', obj='Kuala_Lumpur_Sentral_railway_station')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wWSLubPoxzfo",
        "outputId": "8d114c6a-769c-4bed-a98e-f5acd45a33ad"
      },
      "source": [
        "corpus.get_examples_for_entities(kbt.sbj, kbt.obj)[0].middle"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'it was just a quick 10-minute walk to'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyxF81K_x1i5",
        "outputId": "e0686abf-a949-43f3-817f-d0da01f5395a"
      },
      "source": [
        "simple_bag_of_words_featurizer(kb.kb_triples[0], corpus, Counter())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'10-minute': 1,\n",
              "         'a': 1,\n",
              "         'it': 1,\n",
              "         'just': 1,\n",
              "         'quick': 1,\n",
              "         'the': 1,\n",
              "         'to': 2,\n",
              "         'walk': 1,\n",
              "         'was': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0ZHAW7Xx8sQ"
      },
      "source": [
        "Converting the datasets of `KBTriples` into feature matrices so that ML algos provided by `sklearn` can be used :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdnVACWox3rO"
      },
      "source": [
        "kbts_by_rel, labels_by_rel = dataset.build_dataset()\n",
        "\n",
        "featurized = dataset.featurize(kbts_by_rel, featurizers=[simple_bag_of_words_featurizer])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wemtdxCycZI"
      },
      "source": [
        "***Experiments***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9B2FxQyyPE2"
      },
      "source": [
        "train_result = rel_ext.train_models(\n",
        "    splits,\n",
        "    featurizers=[simple_bag_of_words_featurizer])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sdKfJWjyoyv"
      },
      "source": [
        "predictions, true_labels = rel_ext.predict(\n",
        "    splits, train_result, split_name='dev')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoqYrbkOyrEX",
        "outputId": "678a0a79-2d68-4f86-87da-e22c9ebe4d2d"
      },
      "source": [
        "\n",
        "rel_ext.evaluate_predictions(predictions, true_labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "relation              precision     recall    f-score    support       size\n",
            "------------------    ---------  ---------  ---------  ---------  ---------\n",
            "adjoins                   0.886      0.383      0.702        407       7057\n",
            "author                    0.790      0.521      0.716        657       7307\n",
            "capital                   0.633      0.246      0.481        126       6776\n",
            "contains                  0.786      0.601      0.740       4487      11137\n",
            "film_performance          0.815      0.579      0.754        984       7634\n",
            "founders                  0.836      0.424      0.700        469       7119\n",
            "genre                     0.547      0.171      0.380        205       6855\n",
            "has_sibling               0.812      0.242      0.551        625       7275\n",
            "has_spouse                0.885      0.336      0.666        754       7404\n",
            "is_a                      0.650      0.210      0.458        618       7268\n",
            "nationality               0.588      0.174      0.398        386       7036\n",
            "parents                   0.870      0.533      0.773        390       7040\n",
            "place_of_birth            0.671      0.202      0.458        282       6932\n",
            "place_of_death            0.564      0.105      0.301        209       6859\n",
            "profession                0.626      0.201      0.440        308       6958\n",
            "worked_at                 0.708      0.264      0.530        303       6953\n",
            "------------------    ---------  ---------  ---------  ---------  ---------\n",
            "macro-average             0.729      0.325      0.566      11210     117610\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5656246770981269"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b35ZilyQytSC",
        "outputId": "703ab0a9-d0d8-4514-ebf6-b89320ec6d8e"
      },
      "source": [
        "_ = rel_ext.experiment(\n",
        "    splits,\n",
        "    featurizers=[simple_bag_of_words_featurizer])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "relation              precision     recall    f-score    support       size\n",
            "------------------    ---------  ---------  ---------  ---------  ---------\n",
            "adjoins                   0.886      0.383      0.702        407       7057\n",
            "author                    0.790      0.521      0.716        657       7307\n",
            "capital                   0.633      0.246      0.481        126       6776\n",
            "contains                  0.786      0.601      0.740       4487      11137\n",
            "film_performance          0.815      0.579      0.754        984       7634\n",
            "founders                  0.836      0.424      0.700        469       7119\n",
            "genre                     0.547      0.171      0.380        205       6855\n",
            "has_sibling               0.812      0.242      0.551        625       7275\n",
            "has_spouse                0.885      0.336      0.666        754       7404\n",
            "is_a                      0.650      0.210      0.458        618       7268\n",
            "nationality               0.588      0.174      0.398        386       7036\n",
            "parents                   0.870      0.533      0.773        390       7040\n",
            "place_of_birth            0.671      0.202      0.458        282       6932\n",
            "place_of_death            0.564      0.105      0.301        209       6859\n",
            "profession                0.626      0.201      0.440        308       6958\n",
            "worked_at                 0.708      0.264      0.530        303       6953\n",
            "------------------    ---------  ---------  ---------  ---------  ---------\n",
            "macro-average             0.729      0.325      0.566      11210     117610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILixjKU0y1uW"
      },
      "source": [
        "# ***Analysis***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_4_A6YvyzXu",
        "outputId": "a0c4404f-4bda-4d48-9f9f-9ba7dc01681b"
      },
      "source": [
        "rel_ext.examine_model_weights(train_result)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Highest and lowest feature weights for relation adjoins:\n",
            "\n",
            "     2.457 Taluks\n",
            "     2.457 Valais\n",
            "     2.403 Córdoba\n",
            "     ..... .....\n",
            "    -1.155 Ireland\n",
            "    -1.157 America\n",
            "    -1.166 for\n",
            "\n",
            "Highest and lowest feature weights for relation author:\n",
            "\n",
            "     2.852 author\n",
            "     2.572 books\n",
            "     2.433 writer\n",
            "     ..... .....\n",
            "    -2.463 Alice\n",
            "    -3.000 Daisy\n",
            "    -6.948 1865\n",
            "\n",
            "Highest and lowest feature weights for relation capital:\n",
            "\n",
            "     3.512 capital\n",
            "     1.685 km\n",
            "     1.579 posted\n",
            "     ..... .....\n",
            "    -1.328 and\n",
            "    -1.350 state\n",
            "    -1.996 Dehradun\n",
            "\n",
            "Highest and lowest feature weights for relation contains:\n",
            "\n",
            "     2.764 third-largest\n",
            "     2.337 bordered\n",
            "     2.110 attended\n",
            "     ..... .....\n",
            "    -2.235 band\n",
            "    -2.479 who\n",
            "    -6.034 Bronx\n",
            "\n",
            "Highest and lowest feature weights for relation film_performance:\n",
            "\n",
            "     4.073 starring\n",
            "     3.762 opposite\n",
            "     3.378 alongside\n",
            "     ..... .....\n",
            "    -2.079 spy\n",
            "    -2.171 Tamil\n",
            "    -3.571 Mohabbatein\n",
            "\n",
            "Highest and lowest feature weights for relation founders:\n",
            "\n",
            "     3.886 founder\n",
            "     3.876 founded\n",
            "     3.075 co-founder\n",
            "     ..... .....\n",
            "    -1.299 series\n",
            "    -1.526 novel\n",
            "    -1.553 band\n",
            "\n",
            "Highest and lowest feature weights for relation genre:\n",
            "\n",
            "     3.017 series\n",
            "     2.921 game\n",
            "     2.675 album\n",
            "     ..... .....\n",
            "    -1.372 ;\n",
            "    -1.466 and\n",
            "    -1.757 at\n",
            "\n",
            "Highest and lowest feature weights for relation has_sibling:\n",
            "\n",
            "     4.771 brother\n",
            "     4.077 sister\n",
            "     3.050 nephew\n",
            "     ..... .....\n",
            "    -1.551 Christopher\n",
            "    -1.628 Her\n",
            "    -1.803 where\n",
            "\n",
            "Highest and lowest feature weights for relation has_spouse:\n",
            "\n",
            "     5.092 wife\n",
            "     4.436 widow\n",
            "     4.381 married\n",
            "     ..... .....\n",
            "    -1.334 VIII\n",
            "    -1.488 philanthropist\n",
            "    -1.635 grandson\n",
            "\n",
            "Highest and lowest feature weights for relation is_a:\n",
            "\n",
            "     2.791 \n",
            "     2.584 philosopher\n",
            "     2.236 replaced\n",
            "     ..... .....\n",
            "    -2.951 Talpidae\n",
            "    -3.716 widespread\n",
            "    -5.558 characin\n",
            "\n",
            "Highest and lowest feature weights for relation nationality:\n",
            "\n",
            "     2.731 born\n",
            "     1.952 Pinky\n",
            "     1.841 caliph\n",
            "     ..... .....\n",
            "    -1.420 and\n",
            "    -1.459 American\n",
            "    -1.469 or\n",
            "\n",
            "Highest and lowest feature weights for relation parents:\n",
            "\n",
            "     5.085 son\n",
            "     4.736 daughter\n",
            "     4.017 father\n",
            "     ..... .....\n",
            "    -2.301 Kelly\n",
            "    -2.519 Jolie\n",
            "    -2.647 Gamal\n",
            "\n",
            "Highest and lowest feature weights for relation place_of_birth:\n",
            "\n",
            "     3.819 born\n",
            "     2.559 birthplace\n",
            "     2.237 mayor\n",
            "     ..... .....\n",
            "    -1.182 state\n",
            "    -1.451 or\n",
            "    -1.502 and\n",
            "\n",
            "Highest and lowest feature weights for relation place_of_death:\n",
            "\n",
            "     2.343 died\n",
            "     1.852 where\n",
            "     1.844 assassinated\n",
            "     ..... .....\n",
            "    -1.130 ;\n",
            "    -1.219 and\n",
            "    -1.248 Siege\n",
            "\n",
            "Highest and lowest feature weights for relation profession:\n",
            "\n",
            "     3.392 \n",
            "     2.471 philosopher\n",
            "     2.436 American\n",
            "     ..... .....\n",
            "    -1.290 in\n",
            "    -1.359 from\n",
            "    -1.926 on\n",
            "\n",
            "Highest and lowest feature weights for relation worked_at:\n",
            "\n",
            "     3.056 head\n",
            "     2.985 president\n",
            "     2.838 professor\n",
            "     ..... .....\n",
            "    -1.126 NASA\n",
            "    -1.322 region\n",
            "    -1.744 or\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_PZy_IuzJQS"
      },
      "source": [
        "***Discovering New Relation Instances***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3YKe905y8r3",
        "outputId": "e2d2d0d3-909a-437e-f367-8919934293bd"
      },
      "source": [
        "rel_ext.find_new_relation_instances(\n",
        "    dataset,\n",
        "    featurizers=[simple_bag_of_words_featurizer])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Highest probability examples for relation adjoins:\n",
            "\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Canada', obj='Vancouver')\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Vancouver', obj='Canada')\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Lahore', obj='Pakistan')\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Pakistan', obj='Lahore')\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Atlantic_Ocean', obj='Mexico')\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Mexico', obj='Atlantic_Ocean')\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Blue_Ridge_Mountains', obj='Appalachian_Mountains')\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Appalachian_Mountains', obj='Blue_Ridge_Mountains')\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Sicily', obj='Italy')\n",
            "     1.000 KBTriple(rel='adjoins', sbj='Italy', obj='Sicily')\n",
            "\n",
            "Highest probability examples for relation author:\n",
            "\n",
            "     1.000 KBTriple(rel='author', sbj='Dante_Alighieri', obj='Divine_Comedy')\n",
            "     1.000 KBTriple(rel='author', sbj='Comic_book', obj='Marvel_Comics')\n",
            "     1.000 KBTriple(rel='author', sbj='Charles_Dickens', obj='A_Christmas_Carol')\n",
            "     1.000 KBTriple(rel='author', sbj='A_Christmas_Carol', obj='Charles_Dickens')\n",
            "     1.000 KBTriple(rel='author', sbj='The_Doors_of_Perception', obj='Aldous_Huxley')\n",
            "     1.000 KBTriple(rel='author', sbj='Brave_New_World', obj='Aldous_Huxley')\n",
            "     1.000 KBTriple(rel='author', sbj='Aldous_Huxley', obj='The_Doors_of_Perception')\n",
            "     1.000 KBTriple(rel='author', sbj='Pride_and_Prejudice', obj='Jane_Austen')\n",
            "     1.000 KBTriple(rel='author', sbj='Aldous_Huxley', obj='Brave_New_World')\n",
            "     1.000 KBTriple(rel='author', sbj='Divine_Comedy', obj='Dante_Alighieri')\n",
            "\n",
            "Highest probability examples for relation capital:\n",
            "\n",
            "     1.000 KBTriple(rel='capital', sbj='Bangladesh', obj='Dhaka')\n",
            "     1.000 KBTriple(rel='capital', sbj='Dhaka', obj='Bangladesh')\n",
            "     1.000 KBTriple(rel='capital', sbj='Lucknow', obj='Uttar_Pradesh')\n",
            "     1.000 KBTriple(rel='capital', sbj='Uttar_Pradesh', obj='Lucknow')\n",
            "     1.000 KBTriple(rel='capital', sbj='Sichuan', obj='Chengdu')\n",
            "     1.000 KBTriple(rel='capital', sbj='Chengdu', obj='Sichuan')\n",
            "     1.000 KBTriple(rel='capital', sbj='Delhi', obj='India')\n",
            "     1.000 KBTriple(rel='capital', sbj='India', obj='Delhi')\n",
            "     1.000 KBTriple(rel='capital', sbj='Bandung', obj='West_Java')\n",
            "     1.000 KBTriple(rel='capital', sbj='West_Java', obj='Bandung')\n",
            "\n",
            "Highest probability examples for relation contains:\n",
            "\n",
            "     1.000 KBTriple(rel='contains', sbj='Bangladesh', obj='Dhaka')\n",
            "     1.000 KBTriple(rel='contains', sbj='Australia', obj='Melbourne')\n",
            "     1.000 KBTriple(rel='contains', sbj='Lahore', obj='Pakistan')\n",
            "     1.000 KBTriple(rel='contains', sbj='Canada', obj='Edmonton')\n",
            "     1.000 KBTriple(rel='contains', sbj='Australia', obj='Sydney')\n",
            "     1.000 KBTriple(rel='contains', sbj='Canada', obj='Vancouver')\n",
            "     1.000 KBTriple(rel='contains', sbj='Pakistan', obj='Lahore')\n",
            "     1.000 KBTriple(rel='contains', sbj='Naples', obj='Campania')\n",
            "     1.000 KBTriple(rel='contains', sbj='Vancouver', obj='Canada')\n",
            "     1.000 KBTriple(rel='contains', sbj='Dubai', obj='United_Arab_Emirates')\n",
            "\n",
            "Highest probability examples for relation film_performance:\n",
            "\n",
            "     1.000 KBTriple(rel='film_performance', sbj='Amitabh_Bachchan', obj='Mohabbatein')\n",
            "     1.000 KBTriple(rel='film_performance', sbj='Mohabbatein', obj='Amitabh_Bachchan')\n",
            "     1.000 KBTriple(rel='film_performance', sbj='Sonakshi_Sinha', obj='Akshay_Kumar')\n",
            "     1.000 KBTriple(rel='film_performance', sbj='Akshay_Kumar', obj='Sonakshi_Sinha')\n",
            "     1.000 KBTriple(rel='film_performance', sbj='De-Lovely', obj='Kevin_Kline')\n",
            "     1.000 KBTriple(rel='film_performance', sbj='Kevin_Kline', obj='De-Lovely')\n",
            "     1.000 KBTriple(rel='film_performance', sbj='Charles_Dickens', obj='A_Christmas_Carol')\n",
            "     1.000 KBTriple(rel='film_performance', sbj='A_Christmas_Carol', obj='Charles_Dickens')\n",
            "     1.000 KBTriple(rel='film_performance', sbj='Kaho_Naa..._Pyaar_Hai', obj='Hrithik_Roshan')\n",
            "     1.000 KBTriple(rel='film_performance', sbj='Hrithik_Roshan', obj='Kaho_Naa..._Pyaar_Hai')\n",
            "\n",
            "Highest probability examples for relation founders:\n",
            "\n",
            "     1.000 KBTriple(rel='founders', sbj='Louis_Chevrolet', obj='William_C._Durant')\n",
            "     1.000 KBTriple(rel='founders', sbj='Homer', obj='Iliad')\n",
            "     1.000 KBTriple(rel='founders', sbj='William_C._Durant', obj='Louis_Chevrolet')\n",
            "     1.000 KBTriple(rel='founders', sbj='Iliad', obj='Homer')\n",
            "     1.000 KBTriple(rel='founders', sbj='Marvel_Comics', obj='Stan_Lee')\n",
            "     1.000 KBTriple(rel='founders', sbj='Stan_Lee', obj='Marvel_Comics')\n",
            "     1.000 KBTriple(rel='founders', sbj='Genghis_Khan', obj='Mongol_Empire')\n",
            "     1.000 KBTriple(rel='founders', sbj='Mongol_Empire', obj='Genghis_Khan')\n",
            "     1.000 KBTriple(rel='founders', sbj='Elon_Musk', obj='SpaceX')\n",
            "     1.000 KBTriple(rel='founders', sbj='SpaceX', obj='Elon_Musk')\n",
            "\n",
            "Highest probability examples for relation genre:\n",
            "\n",
            "     1.000 KBTriple(rel='genre', sbj='Hal_Holbrook', obj='Mark_Twain_Tonight')\n",
            "     1.000 KBTriple(rel='genre', sbj='Mark_Twain_Tonight', obj='Hal_Holbrook')\n",
            "     0.992 KBTriple(rel='genre', sbj='Andrew_Garfield', obj='Sam_Raimi')\n",
            "     0.992 KBTriple(rel='genre', sbj='Sam_Raimi', obj='Andrew_Garfield')\n",
            "     0.990 KBTriple(rel='genre', sbj='Louisa_May_Alcott', obj='Little_Women')\n",
            "     0.990 KBTriple(rel='genre', sbj='Little_Women', obj='Louisa_May_Alcott')\n",
            "     0.990 KBTriple(rel='genre', sbj='Pink_Floyd', obj='The_Dark_Side_of_the_Moon')\n",
            "     0.990 KBTriple(rel='genre', sbj='The_Dark_Side_of_the_Moon', obj='Pink_Floyd')\n",
            "     0.988 KBTriple(rel='genre', sbj='The_Faculty', obj='Robert_Rodriguez')\n",
            "     0.988 KBTriple(rel='genre', sbj='Robert_Rodriguez', obj='The_Faculty')\n",
            "\n",
            "Highest probability examples for relation has_sibling:\n",
            "\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='Gutzon_Borglum', obj='Lincoln_Borglum')\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='Lincoln_Borglum', obj='Gutzon_Borglum')\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='April_Margera', obj='Jess_Margera')\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='Jess_Margera', obj='April_Margera')\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='Philip_II_of_Macedon', obj='Alexander_the_Great')\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='Alexander_the_Great', obj='Philip_II_of_Macedon')\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='Rufus_Wainwright', obj='Kate_McGarrigle')\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='Kate_McGarrigle', obj='Rufus_Wainwright')\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='William_Lawrence_Bragg', obj='William_Henry_Bragg')\n",
            "     1.000 KBTriple(rel='has_sibling', sbj='William_Henry_Bragg', obj='William_Lawrence_Bragg')\n",
            "\n",
            "Highest probability examples for relation has_spouse:\n",
            "\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='Akhenaten', obj='Tutankhamun')\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='Tutankhamun', obj='Akhenaten')\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='Douglas_Fairbanks', obj='United_Artists')\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='United_Artists', obj='Douglas_Fairbanks')\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='Louis_Chevrolet', obj='William_C._Durant')\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='William_C._Durant', obj='Louis_Chevrolet')\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='Nicole_Brown_Simpson', obj='Ronald_Goldman')\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='Ronald_Goldman', obj='Nicole_Brown_Simpson')\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='England', obj='Charles_II_of_England')\n",
            "     1.000 KBTriple(rel='has_spouse', sbj='Charles_II_of_England', obj='England')\n",
            "\n",
            "Highest probability examples for relation is_a:\n",
            "\n",
            "     1.000 KBTriple(rel='is_a', sbj='Felidae', obj='Panthera')\n",
            "     1.000 KBTriple(rel='is_a', sbj='Canada', obj='Vancouver')\n",
            "     1.000 KBTriple(rel='is_a', sbj='Vancouver', obj='Canada')\n",
            "     1.000 KBTriple(rel='is_a', sbj='Panthera', obj='Felidae')\n",
            "     1.000 KBTriple(rel='is_a', sbj='South_Korea', obj='Automobile')\n",
            "     1.000 KBTriple(rel='is_a', sbj='Automobile', obj='South_Korea')\n",
            "     1.000 KBTriple(rel='is_a', sbj='Hibiscus', obj='Malvaceae')\n",
            "     1.000 KBTriple(rel='is_a', sbj='Malvaceae', obj='Hibiscus')\n",
            "     1.000 KBTriple(rel='is_a', sbj='Bird', obj='Phasianidae')\n",
            "     1.000 KBTriple(rel='is_a', sbj='Phasianidae', obj='Bird')\n",
            "\n",
            "Highest probability examples for relation nationality:\n",
            "\n",
            "     1.000 KBTriple(rel='nationality', sbj='Roman_Empire', obj='Titus')\n",
            "     1.000 KBTriple(rel='nationality', sbj='Titus', obj='Roman_Empire')\n",
            "     1.000 KBTriple(rel='nationality', sbj='Genghis_Khan', obj='Mongol_Empire')\n",
            "     1.000 KBTriple(rel='nationality', sbj='Mongol_Empire', obj='Genghis_Khan')\n",
            "     1.000 KBTriple(rel='nationality', sbj='Cambodia', obj='Norodom_Sihamoni')\n",
            "     1.000 KBTriple(rel='nationality', sbj='Norodom_Sihamoni', obj='Cambodia')\n",
            "     0.999 KBTriple(rel='nationality', sbj='April_Margera', obj='Jess_Margera')\n",
            "     0.999 KBTriple(rel='nationality', sbj='Jess_Margera', obj='April_Margera')\n",
            "     0.999 KBTriple(rel='nationality', sbj='Comic_book', obj='Marvel_Comics')\n",
            "     0.999 KBTriple(rel='nationality', sbj='Marvel_Comics', obj='Comic_book')\n",
            "\n",
            "Highest probability examples for relation parents:\n",
            "\n",
            "     1.000 KBTriple(rel='parents', sbj='Gutzon_Borglum', obj='Lincoln_Borglum')\n",
            "     1.000 KBTriple(rel='parents', sbj='Philip_II_of_Macedon', obj='Alexander_the_Great')\n",
            "     1.000 KBTriple(rel='parents', sbj='Alexander_the_Great', obj='Philip_II_of_Macedon')\n",
            "     1.000 KBTriple(rel='parents', sbj='Lincoln_Borglum', obj='Gutzon_Borglum')\n",
            "     1.000 KBTriple(rel='parents', sbj='Thomas_Boleyn,_1st_Earl_of_Wiltshire', obj='Anne_Boleyn')\n",
            "     1.000 KBTriple(rel='parents', sbj='Anne_Boleyn', obj='Thomas_Boleyn,_1st_Earl_of_Wiltshire')\n",
            "     1.000 KBTriple(rel='parents', sbj='April_Margera', obj='Jess_Margera')\n",
            "     1.000 KBTriple(rel='parents', sbj='Jess_Margera', obj='April_Margera')\n",
            "     1.000 KBTriple(rel='parents', sbj='John_Bonham', obj='Jason_Bonham')\n",
            "     1.000 KBTriple(rel='parents', sbj='Jason_Bonham', obj='John_Bonham')\n",
            "\n",
            "Highest probability examples for relation place_of_birth:\n",
            "\n",
            "     0.997 KBTriple(rel='place_of_birth', sbj='Bagmati_Zone', obj='Nepal')\n",
            "     0.997 KBTriple(rel='place_of_birth', sbj='Nepal', obj='Bagmati_Zone')\n",
            "     0.995 KBTriple(rel='place_of_birth', sbj='Roman_Empire', obj='Titus')\n",
            "     0.995 KBTriple(rel='place_of_birth', sbj='Titus', obj='Roman_Empire')\n",
            "     0.994 KBTriple(rel='place_of_birth', sbj='Lumbini', obj='Gautama_Buddha')\n",
            "     0.994 KBTriple(rel='place_of_birth', sbj='Gautama_Buddha', obj='Lumbini')\n",
            "     0.994 KBTriple(rel='place_of_birth', sbj='Sichuan', obj='Chengdu')\n",
            "     0.994 KBTriple(rel='place_of_birth', sbj='Chengdu', obj='Sichuan')\n",
            "     0.993 KBTriple(rel='place_of_birth', sbj='England', obj='Elizabeth_I_of_England')\n",
            "     0.993 KBTriple(rel='place_of_birth', sbj='Elizabeth_I_of_England', obj='England')\n",
            "\n",
            "Highest probability examples for relation place_of_death:\n",
            "\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='Roman_Empire', obj='Titus')\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='Titus', obj='Roman_Empire')\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='Philip_II_of_Macedon', obj='Alexander_the_Great')\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='Alexander_the_Great', obj='Philip_II_of_Macedon')\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='Genghis_Khan', obj='Mongol_Empire')\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='Mongol_Empire', obj='Genghis_Khan')\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='England', obj='Elizabeth_I_of_England')\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='Elizabeth_I_of_England', obj='England')\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='Roman_Empire', obj='Tiberius_Julius_Alexander')\n",
            "     1.000 KBTriple(rel='place_of_death', sbj='Tiberius_Julius_Alexander', obj='Roman_Empire')\n",
            "\n",
            "Highest probability examples for relation profession:\n",
            "\n",
            "     1.000 KBTriple(rel='profession', sbj='Canada', obj='Vancouver')\n",
            "     1.000 KBTriple(rel='profession', sbj='Vancouver', obj='Canada')\n",
            "     1.000 KBTriple(rel='profession', sbj='Louisa_May_Alcott', obj='Little_Women')\n",
            "     1.000 KBTriple(rel='profession', sbj='Little_Women', obj='Louisa_May_Alcott')\n",
            "     1.000 KBTriple(rel='profession', sbj='Kaho_Naa..._Pyaar_Hai', obj='Hrithik_Roshan')\n",
            "     1.000 KBTriple(rel='profession', sbj='Hrithik_Roshan', obj='Kaho_Naa..._Pyaar_Hai')\n",
            "     0.999 KBTriple(rel='profession', sbj='Actor', obj='Screenwriter')\n",
            "     0.999 KBTriple(rel='profession', sbj='Screenwriter', obj='Actor')\n",
            "     0.999 KBTriple(rel='profession', sbj='Musician', obj='Multi-instrumentalist')\n",
            "     0.999 KBTriple(rel='profession', sbj='Multi-instrumentalist', obj='Musician')\n",
            "\n",
            "Highest probability examples for relation worked_at:\n",
            "\n",
            "     1.000 KBTriple(rel='worked_at', sbj='Louis_Chevrolet', obj='William_C._Durant')\n",
            "     1.000 KBTriple(rel='worked_at', sbj='William_C._Durant', obj='Louis_Chevrolet')\n",
            "     1.000 KBTriple(rel='worked_at', sbj='Homer', obj='Iliad')\n",
            "     1.000 KBTriple(rel='worked_at', sbj='Iliad', obj='Homer')\n",
            "     1.000 KBTriple(rel='worked_at', sbj='Comic_book', obj='Marvel_Comics')\n",
            "     1.000 KBTriple(rel='worked_at', sbj='Marvel_Comics', obj='Comic_book')\n",
            "     1.000 KBTriple(rel='worked_at', sbj='Marvel_Comics', obj='Stan_Lee')\n",
            "     1.000 KBTriple(rel='worked_at', sbj='Stan_Lee', obj='Marvel_Comics')\n",
            "     1.000 KBTriple(rel='worked_at', sbj='Elon_Musk', obj='SpaceX')\n",
            "     1.000 KBTriple(rel='worked_at', sbj='SpaceX', obj='Elon_Musk')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7svo6pUQzAFI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}